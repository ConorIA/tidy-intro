---
title: "A tidy lightning review: HDD and energy demand case study"
output: 
  html_notebook
---

You have been asked by Toronto Hydro to perform a rudimentary study of winter energy demand due to heating in downtown Toronto. The period of study will be the 30-year period from 1989 to 2018. Energy demand data do not cover this period completely, so you will use temperature data as a proxy. 

First, load the **tidyverse** package, along with **lubridate**.

```{r}
library(tidyverse)
library(lubridate)
```

Now read in your information, which is contained in the _data_ folder. _Note that I am suppressing the noisy output here._

```{r, message=FALSE, warning=FALSE}
dat <- read_csv("https://raw.githubusercontent.com/ConorIA/tidy-intro/master/data/5051-daily-1989-2018.csv")
```

This dataset is a minimally edited export from the Environment and Climate Change Canada Historical Data Archive (http://climate.weather.gc.ca/). The data were collected at the "Toronto" station, which is located on the St. George campus, and has been in operation since 1840, the longest climatological record in Canada. Let's take a look at the data contained in the _.csv_ file. 

```{r}
glimpse(dat)
```

By golly those column names are verbose! In R, including in the tidyverse, we have to enclose names that contain spaces in quotation marks ("") or backticks (``). This is a drag! Let's rename some of these columns, to make them easier to type. 

```{r, eval=FALSE}
dat <- dat %>% rename(Date = `Date/Time`, MaxTemp = `Max Temp (°C)`,
                      MinTemp = `Min Temp (°C)`, MeanTemp = `Mean Temp (°C)`)
```

Or, if, like me, your computer complains about Unicode characters ...

```{r}
dat <- dat %>% rename(Date = `Date/Time`, MaxTemp = "Max Temp (\u00B0C)",
                      MinTemp = "Min Temp (\u00B0C)", MeanTemp = "Mean Temp (\u00B0C)")
```

Now you can check the column names again.

```{r}
glimpse(dat)
```

Much better!

***

While things like wind and snow might indirectly affect our energy use, for the purposes of our current study, they are not useful. Let's use the `dplyr::select()` function to whittle down our data frame to only those variables that are of interest to us. 

```{r}
dat <- dat %>% select(Date, MaxTemp, MinTemp, MeanTemp)
```

Now you can take a look at the first few rows by printing the table. Remember, since **readr** automatically reads table data to a tibble, we don't have to worry about using `head()`, because the printed rows are capped at 10 automatically. 

```{r}
dat
```

We have learned the difference between "wide" and "long" data frames, and have seen that narrow data frames are much more convenient to plot using **ggplot2** due to the faceting magic implemented by the package. Let's create a long data frame for our data. 

```{r}
dat_long <- dat %>%
  pivot_longer(cols = -Date, names_to = "Variable", values_to = "Value")
```

Great. Let's make a first plot for a quick visual confirmation that our data is complete and doesn't contain wildly incorrect observations.

```{r warning=FALSE}
ggplot(dat_long, aes(x = Date, y = Value, colour = Variable)) +
  geom_line() +
  ggtitle("Daily Temperature at Toronto (5051), 1989\u20122018") +
  ylab("Temperature (\u00B0C)")
```

Uhh ohh! Something doesn't look right! It seems that our data drops off a cliff sometime in the early 2000s. What did we do wrong? Sometime between 2002 and 2003, Environment Canada made some changes in their weather station network. Station 5051 continues to collect precipitation data (to date), however the temperature data are now collected at station 31688. These stations are co-located, so the change is little more than a shift in name and station code (although there is a brief period where the two stations overlap and the temperature values _do_ differ by a few tenths of a degree Celsius on some observations, but we'll take for granted that these differences are inconsequential). 

Let's unlock the power of the tidyverse for this one. Here we will:

- read in the data for station 31688 with `readr::read_csv()`
- rename **and** select the columns that we are interested in using `dplyr::select()`
- filter both of our data frames to data before / after January 1, 2003 using `dplyr::filter()`
- append the new data frame to the original one using `dplyr::bind_rows()`

```{r, message=FALSE, warning=FALSE}
dat2 <- read_csv("https://raw.githubusercontent.com/ConorIA/tidy-intro/master/data/31688-daily-2001-2018.csv") %>%
  select(Date = `Date/Time`, MaxTemp = "Max Temp (\u00B0C)",
         MinTemp = "Min Temp (\u00B0C)", MeanTemp = "Mean Temp (\u00B0C)") %>%
  filter(Date >= "2003-01-01")

dat <- dat %>% filter(Date < "2003-01-01") %>% bind_rows(dat2)
```

Let's re-do our "quick check" plot using the amalgamated dataset.

```{r}
dat %>%
  pivot_longer(cols = -Date, names_to = "Variable", values_to = "Value") %>%
  ggplot(aes(x = Date, y = Value, colour = Variable)) +
    geom_line() +
    ggtitle("Daily temperature at Toronto (5051 and 31688), 1989\u20122018") +
    ylab("Temperature (\u00B0C)")
```

Much better. On to our analysis.

***

We want to look at _winter_ energy use in Toronto. A climatological winter is calculated from December to February (DJF). We need to be careful here. If we group our values by year, and then aggregate the values for the winter months, then we actually end up with JF...D, where the December that corresponds to the _following_ winter is grouped with the January and February of a given winter. That's poor form! Let's add a new column to our data frame. We'll add 1 to the "year" of all of our Decembers. This way, December 1989 will correctly be attributed to winter 1990 (or, more explicitly winter 1989/90).

```{r}
dat_win <- dat %>% filter(month(Date) %in% c(1, 2, 12)) %>%
  mutate(Winter = ifelse(month(Date) == 12, year(Date) + 1, year(Date)))
```

Let's take a look at the first three and last three rows in our table. Notice that January 1989 remains part of winter 1989, but December 2018 becomes part of winter 2019. 

```{r}
dat_win %>% head(3)
```

```{r}
dat_win %>% tail(3)
```

In the winter, most energy demand is related to space heating, so heating degree days are useful to us. Heating degree days are defined as the degrees of heating (in °C) required to bring the daily mean temperature (`MeanTemp`) up to a base temperature of 18°C. As an example, if `MeanTemp` is $-6.3$°C: 

$$
\textrm{HDD} = 18 - (-6.3) \\
\textrm{HDD} = 24.3
$$
HDDs cannot be negative, so if `MeanTemp` is greater than 18°C, the HDDs for that day are 0. Let's add a new column to our data frame, which will be populated by `18 - MeanTemp` on days when `MeanTemp` is below 18.

```{r}
dat_win <- dat_win %>% select(Winter, MeanTemp) %>%
  mutate(HDD = ifelse(MeanTemp >= 18, 0, 18 - MeanTemp)) %>% print()
```

Great. Let's calculate the average value for each winter. Notice that I am adding a "number of observations" variable `n`. You'll see why in a minute. 

```{r}
dat_win_sum <- dat_win %>% group_by(Winter) %>%
  summarize(MeanTemp = mean(MeanTemp, na.rm = TRUE),
            HDD = mean(HDD, na.rm = TRUE),
            n = n())
```

As you may have noticed already, we have created some incomplete winters in our process. First, winter 1988/89, which is missing data for December 1988. Second, winter 2018/19, which only includes December 2018. We can remove these values by filtering to complete seasons, which contain 90 to 91 daily observations. Let's filter those rows out of the data and plot it.

_Note: There are a few winters in my data set that are missing up to three daily HDD observations. We can probably assume that these values won't impact the average seasonal HDD value by very much, but a more advanced analysis may involve interpolating thesre missing values orsome other treatment._

```{r}
dat_win_sum <- dat_win_sum %>% filter(n >= 90) %>% select(-n)

ggplot(dat_win_sum, aes(x = Winter, y = HDD)) +
  geom_point() +
  geom_smooth() +
  ggtitle("Daily average winter heating degree days at Toronto, 1989\u20122018", subtitle = "Stations 5051 and 31688") +
  ylab("Heating degree days")
```

That plot looks pretty good, however, the x-axis could be made to be more clear. Let's do some very basic string manipulation using **stringr**. Here we will create a new column for the labels. Each label will be created by first subtracting 1 from each winter, adding a forward slash and then appending the last two digits of each winter, e.g. 1990 becomes 1989/90. 

```{r}
dat_win_sum <- dat_win_sum %>% mutate(Label = str_c(Winter - 1, "/", str_sub(Winter, 3, 4)))

ggplot(dat_win_sum, aes(x = Winter, y = HDD)) +
  geom_point() +
  geom_smooth(method = loess) +
  ggtitle("Daily average winter heating degree days at Toronto, 1989\u20122018", subtitle = "Stations 5051 and 31688") +
  ylab("Heating degree days") +
  scale_x_continuous(breaks = dat_win_sum$Winter[seq(1, 29, 4)],
                     labels = dat_win_sum$Label[seq(1, 29, 4)])
```

There we have it! Explicit, customized labels on our x-axis. 

***

So, are HDDs a good proxy for energy demand data? Let's take a look at some real energy demand data for the "Toronto" zone. These daily demand data were adapted form the Independent Electricity System Operator (IESO) hourly zonal demand data: http://reports.ieso.ca/public/DemandZonal/. 

```{r, message=FALSE}
demand <- read_csv("https://raw.githubusercontent.com/ConorIA/tidy-intro/master/data/TO_energy_demand.csv") %>% print()
```

As we can see from the column names, the data are grouped by date, and include three variables: daily minimum demand, daily maximum demand, and average daily demand. Let's convert our data from daily to seasonal. In this case, rather than directly creating a winter dataset, let's get some more practice using `dplyr::case_when()` to create a four-season dataset.

```{r}
demand <- demand %>% mutate(Year = ifelse(month(Date) == 12, year(Date) + 1, year(Date)),
                            Season = case_when(
                              month(Date) %in% 3:5  ~ 2,
                              month(Date) %in% 6:8  ~ 3,
                              month(Date) %in% 9:11 ~ 4,
                              TRUE ~ 1)) %>% print()
```

Now that we have shifted the year for our Decembers, and have labelled each value with a season, we can group our data and calculate the total demand. Here I will first group by `Year` and `Season`, then add an additional grouping variable, the number of observations in each group `n`. Using those columns, I will calculate the mean and standard deviation of each of our three variables of interest. 

```{r}
demand_agg <- demand %>%
  group_by(Year, Season) %>%
  group_by(n = n(), .add = TRUE) %>%
  select(-Date) %>%
  summarize_all(list(mean = mean, sd = sd)) %>%
  filter(n >= 90) %>% print()
```

Great. Let's plot the mean seasonal demand against the year. We'll add error bars showing the standard error of the mean.  

```{r warning=FALSE}
win_demand <- demand_agg %>%
  filter(Season ==1) %>%
  mutate(se = Mean_sd / sqrt(n))

ggplot(win_demand, aes(x = Year, y = Mean_mean)) + geom_point() +
  geom_errorbar(aes(ymin = Mean_mean - se, ymax = Mean_mean + se)) +
  ggtitle("Winter energy demand in Toronto, 2003\u20122018") +
  ylab("Average energy demand (MW)")
```

There are a couple of high-demand winters: 2014/15 and 2015/16. Those winters were characterized by very long periods of cold weather. It looks like energy demand may, indeed, be dependent on the weather. 

***

Let's join our HDD table to our energy demand table. Note that in the HDD table, our winters are called `Winter`, whereas in the energy table, we used `Year`. We'll have to ask `dplyr::left_join()` to explicitly use these two variables as the common column.

```{r}
dat_win_demand <- left_join(dat_win_sum,
                            win_demand,
                            by = c("Winter" = "Year")) %>% print()
```

You'll notice that missing values (`NA`) are inserted for the dates for which we do not have energy demand data. Before we move on, let's clean up our table a little. 

```{r}
dat_win_demand <- dat_win_demand %>% select(Winter, Label, HDD, Demand = Mean_mean) %>% print()
```

Now let's visualize our data. First, let's try plotting both variables, using a secondary axis in **ggplot2**. Secondary axes in **ggplot2** are based on some transformation of the values of one or more series. Here we will take the demand data, and divide each observation by 300. This will put the data in the same ball park as the HDD data. On the secondary axis, we will use a transformation to multiply each  tick mark by 300 so that the value is representative of the true energy demand data.

```{r warning=FALSE}
ggplot(dat_win_demand, aes(x = Winter)) + 
  geom_line(aes(y = HDD, colour = "HDD")) + 
  geom_line(aes(y = Demand / 300, colour = "Demand")) +
  scale_y_continuous(sec.axis = sec_axis(~. * 300, name = "Energy demand (MW)")) +
  scale_x_continuous(breaks = dat_win_demand$Winter[seq(1, 29, 4)],
                     labels = dat_win_demand$Label[seq(1, 29, 4)]) +
    
  ylab("Avg. dly. heating degree days") + 
  ggtitle("Winter HDD and energy demand at Toronto, 1989\u20122018")
```

Not great. A more elaborate transformation may clean up the graph a little, but let's try something else. 

Another way to visualize two different data sets side-by side is to use a `facet_wrap`. Let's see an example of this too. 

```{r warning=FALSE}
dat_win_demand %>%
  pivot_longer(cols = HDD:Demand, names_to = "Variable", values_to = "value") %>%
  ggplot(aes(x = Winter, y = value)) + geom_line() +
  facet_wrap(~Variable, nrow = 2, scales = "free_y") + ylab("HDD / Energy demand (MW)") + 
  ggtitle("Winter HDD and energy demand at Toronto, 1989\u20122018")
```

Finally, we can plot these variables, one against the other. 

```{r warning=FALSE}
ggplot(dat_win_demand, aes(x = HDD, y = Demand)) +
  geom_point() +
  geom_smooth(method = lm) +
  ggtitle("Wintertime Heating degree days and energy demand in Toronto",
          subtitle = "Winter 1989/90\u20122017/18") +
  ylab("Average energy demand (MW)") +
  xlab("Total Heating degree days")
````

By the looks of it, HDD are an imperfect, but not altogether incorrect proxy for total winter energy demand. 

## Exercise

Now that we have began to explore these data, complete the following exercises.

1. Fit a model to the HDD data and the energy demand data. Is the relationship significant?
2. Repeat the above process for the Summer Season, using Cooling Degree Days, which are the degrees of cooling required to bring the mean temperature _down_ to the base temperature of 18°C. Create the following plots: 
  - A plot of average daily summer CDD
  - A plot of average summer energy demand
  - Either a dual-axis plot or a facet wrapped plot of CDD and energy demand
  - A plot of energy demand over CDD
3. Fit a model to the CDD data and the energy demand data. Is the relationship significant?
4. Which variable shows a stronger relationship to energy demand: HDD or CDD?

Feel free to ask your instructors for help during this exercise. 

### Some formatting tips

If you look at the HTML version of this R notebook, you may find some unsightly characters in the `glimpse()` output, as well as in the cell that loads the **tidyverse** package. This is because these functions use ANSI strings (a sort of text encoding) to output coloured or italic text on the console. These strings are not properly rendered in the HTML and will make your reports ugly. You can beautify them with the following options: 

1. `options(crayon.enabled = FALSE)` : this will disable the ANSI strings all together
2. `options(tidyverse.quiet = TRUE)` : this will completely suppress the **tidyverse** startup messages
3. `library(lubridate, warn.conflicts = FALSE)` : this will suppress the conflict warnings when **lubridate loads**
